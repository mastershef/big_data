{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi generale progetto Big Data, Alessandro Stefani, Cristi Gutu.\n",
    "### Il progetto tratta il problema della classificazione nella rispettiva categoria di news reperite dall'agenzia ANSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importazione funzioni processamento articoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Cristy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from AC import preproc\n",
    "from AC import get_news\n",
    "import inspect\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ottenimento articoli per ogni categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [00:34<00:00, 69.99it/s] \n"
     ]
    }
   ],
   "source": [
    "economia = get_news(\"./articoli_economia/\")\n",
    "cultura = get_news(\"./articoli_cultura/\")\n",
    "tech = get_news(\"./articoli_tech/\")\n",
    "politica = get_news(\"./articoli_politica/\")\n",
    "sport = get_news(\"./articoli_sport/\")\n",
    "cronaca = get_news(\"./articoli_cronaca/\")\n",
    "\n",
    "for articolo in economia:\n",
    "    articolo['categoria'] = \"Economia\"\n",
    "for articolo in cultura:\n",
    "    articolo['categoria'] = \"Cultura\"\n",
    "for articolo in tech:\n",
    "    articolo['categoria'] = \"Tech\"\n",
    "for articolo in politica:\n",
    "    articolo['categoria'] = \"Politica\"\n",
    "for articolo in sport:\n",
    "    articolo['categoria'] = \"Sport\"\n",
    "for articolo in cronaca:\n",
    "    articolo['categoria'] = \"Cronaca\"\n",
    "dati_preprocessati =  preproc(tech + politica + cultura + economia + sport + cronaca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AC import distribuzione_frequenze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importazione moduli necessari per la suddivisione dell'insieme di news in train e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model,metrics\n",
    "from sklearn.dummy import DummyClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suddivisione news in insieme di training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristy\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning:\n",
      "\n",
      "From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 2\n",
    "train_documents,test_documents = train_test_split(dati_preprocessati,random_state=seed, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costruzione della term document matrix e calcolo distribuzione Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "distribuzione_frequenze() got an unexpected keyword argument 'max_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-94d08f1a5552>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtest_cats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"categoria\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_documents\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdistribuzione_frequenze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mngrammi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m#distribuzione_frequenze(test_texts,\"test\",ngrammi=(1,6),min_df=11)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: distribuzione_frequenze() got an unexpected keyword argument 'max_df'"
     ]
    }
   ],
   "source": [
    "docs_texts = [' '.join([word for word in x['testo']] + x['tags'] + x['sottotitolo'] + x['titolo_articolo']) for x in dati_preprocessati]\n",
    "train_texts = [' '.join([word for word in x['testo']] + x['sottotitolo'] + x['titolo_articolo']) for x in train_documents]\n",
    "test_texts = [' '.join([word for word in x['testo']] + x['sottotitolo'] + x['titolo_articolo']) for x in test_documents]\n",
    "\n",
    "docs_cats = [x[\"categoria\"] for x in dati_preprocessati]\n",
    "train_cats = [x[\"categoria\"] for x in train_documents]\n",
    "test_cats = [x[\"categoria\"] for x in test_documents]\n",
    "\n",
    "distribuzione_frequenze(train_texts,\"train\",ngrammi=(8,15),min_df=1,max_df=0.9)\n",
    "#distribuzione_frequenze(test_texts,\"test\",ngrammi=(1,6),min_df=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Nella figura si vede la distribuzione del numero di volte che una parola comapre nei documenti di training e di test\n",
    "##### Esempio: 6 parole compaiono in piu di 500 documenti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costuzione pipeline, per i dati gia' preprocessati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('count_mx', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=1000000, min_df=13,\n",
       "        ngram_range=(1, 8), preprocessor=None, stop_words=None,\n",
       "     ...         min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best'))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "#classificatore_logistico = linear_model.LogisticRegression(random_state=0,solver='lbfgs',multi_class='multinomial')\n",
    "classificatore_albero = DecisionTreeClassifier(  max_depth=20, min_samples_leaf=1, random_state=0 )\n",
    "ldac = Pipeline([\n",
    "    (\"count_mx\",CountVectorizer(ngram_range=(8,10), min_df=1,encoding='utf-8',max_features=1000000, lowercase=True)),\n",
    "    (\"lda\", LatentDirichletAllocation(n_components=20,max_iter=50, learning_method='online',random_state=0)), \n",
    "    (\"classifier\",classificatore_albero)\n",
    "])\n",
    "params = {\n",
    "    'count_mx__ngram_range': (1, 8),\n",
    "    'count_mx__min_df': 13,\n",
    "    'count_mx__max_df': 0.9,\n",
    "    'lda__n_components':8,\n",
    "    'lda__learning_decay':0.5,\n",
    "    'classifier__min_samples_leaf': 1,\n",
    "    'classifier__max_depth': 15\n",
    "}\n",
    "ldac.set_params(**params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting term document matrix via Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('count_mx', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=1000000, min_df=13,\n",
       "        ngram_range=(1, 8), preprocessor=None, stop_words=None,\n",
       "     ...         min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best'))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldac.fit(train_texts,train_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predizione con insieme di test e Costruzione matrice di confusione "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cats = ldac.predict(test_texts)\n",
    "classi = unique_labels(test_cats, pred_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prova con predizione direttamente da articoli nuovi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Cultura'], dtype='<U8')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estrattore_dati.estrattore_articoli_ansa import estrai\n",
    "#p = estrai(\"http://www.ansa.it/sito/notizie/tecnologia/hitech/2019/06/03/amazon-apre-negozio-a-manchester_24353478-6d22-43b4-89d6-32725e95bf09.html\")\n",
    "#p = {\"titolo_articolo\":\"Conte verso l'ultimatum a Lega e M5s e chiede chiarimenti sullo sblocca-cantieri\",\"testo\":\"Il discorso di ConteNegli ultimi giorni, a chi gli faceva domande sul destino del governo, Giuseppe Conte ha risposto rinviando all'incontro con i giornalisti di \\\"luned\\u00EC\\\". Oggi dunque - a borse chiuse - pronuncer\\u00E0 un discorso molto atteso in cui, presumibilmente, lancer\\u00E0 un aut aut: evocando in qualche modo la possibilit\\u00E0 di dimissioni. Questo nel caso in cui non ci sia un'inversione di tendenza nella rissa continua tra Lega e 5Stelle. E se continuer\\u00E0 la linea di rottura con Bruxelles.repApprofondimentoOggi l'ultimatum di Conte: \\u201CTrattativa con la Ue o lascio\\u201Ddi TOMMASO CIRIACONel mirino di Conte c'\\u00E8 soprattutto Salvini che - dopo il ribaltamento dei rapporti di forza coni 5Stelle - si muove a tutto campo come fosse il presidente del Consiglio. Il malumore di Conte \\u00E8 stato visibile gi\\u00E0 nei giorni scorsi quando ha chiarito: \\\"Gli emendamenti governativi vanno discussi nella sede del governo che \\u00E8 Palazzo Chigi\\\", un riferimento alle modifiche presentate dalla Lega allo Sblocca-cantieri. O quando ha frenato la corsa leghista verso la flat tax.Centinaio: il premier faccia un miracoloIl primo a sperare che il discorso del premier faccia miracoli \\u00E8 il ministro dell'Agricoltura Gian Marco Centinaio, ospite di Circo Massimo su Radio Capital: \\\"Auspico che il presidente Conte faccia un miracolo. Continuo a essere dell'idea che la campagna elettorale \\u00E8 finita e i toni si devono abbassare. Il premier deve ricominciare a far parlare la politica, e soprattutto i due contraenti del contratto, di cose concrete\\\". Ma poi aggiunge che da parte della Lega \\\"c'\\u00E8 la buona volont\\u00E0, ma se non ci dovessero essere le condizioni, se non si riesce a mettersi d'accordo, non vedo alternativa a elezioni\\\".Governo, il ministro Centinaio: \\\"Abbassiamo i toni, Conte faccia il miracolo: l'alternativa \\u00E8 il voto\\\"CondividiSblocca-cantieri e decreto crescitaCi sono due importanti decreti - vicini alla scadenza - ad agitare i rapporti tra i gialloverdi: uno \\u00E8 lo sblocca-cantieri, previsto in aula per domani, su cui si combatte la sfida del Codice degli appalti. La Lega ha presentato un emendamento che intende bloccare il Codice per due anni. Salvini ha detto che frena il Paese, i 5Stelle non sono d'accordo. Il presidente della Commissione parlamentare antimafia - il grillino Nicola Morra - ha detto che il subappalto libero \\u00E8 un \\\"grimaldello\\\" per la criminalit\\u00E0 organizzata.In merito Salvini questa mattina, nell'inaugurare vicino a Vicenza il primo tratto della Pedemontana veneta con il governatore Zaia, ha commentato con una battuta la convocazione ricevuta da Conte per le 17.30 di oggi a Palazzo Chigi: \\\"Oggi ho ricevuto una lettera del presidente del Consiglio che convoca una riunione sullo Sblocca cantieri. Beh, io sono stamattina qui, il cantiere \\u00E8 sbloccato\\\". E sul tema delle infrastrutture, invita il governo a rompere gli indugi sulle grandi opere: \\\"Se uno ha paura cambi mestiere, perch\\u00E8 \\u00E8 il momento del coraggio\\\".E poi c'\\u00E8 il decreto crescita che \\u00E8 oggi in commissione Finanze e domani dovrebbe approdare in aula. Manca l'accordo sul cosiddetto \\\"Salva-Roma\\\" sui debiti della capitale, ma - vista la freddezza tra la sindaca Raggi e Luigi Di Maio - il provvedimento non \\u00E8 pi\\u00F9 considerato una priorit\\u00E0 dai vertici M5S.La risposta Ue alla lettera di TriaArriver\\u00E0 dopodomani la risposta di Bruxelles alla lettera del governo sui conti. Lo ha confermato sabato un portavoce della Commissione. L'avvio di una procedura d'infrazione per il debito \\u00E8 sempre pi\\u00F9 probabile. Con ripercussioni temibili sui mercati. Ma sul governo pesa anche la denuncia di Tria contro la \\\"manina\\\" che ha diffuso la prima versione della lettera (nel mirino i 5Stelle).Resta da capire come si muoveranno le due forze politiche nel rapporto conl'Ue. Luigi Di Maio ha perso, negli ultimi giorni, l'afflato europeista manifestato durante la campagna elettorale. Ma \\u00E8 certo che a fare la voce grossa con Bruxelles, nelle ultime ore, \\u00E8 stato soprattutto Matteo Salvini dicendo: \\\"Vedremo chi ha la testa pi\\u00F9 dura\\\". Ci saranno spaccature su questo tra gli alleati? Di sicuro Conte non sembra intenzionato ad avallare una procedura d'infrazione.La flat taxPer Salvini la flat tax resta una priorit\\u00E0. \\\"Il governo va avanti se mantiene l'impegno di tagliare le tasse, presto e bene\\\", ha ripetuto anche ieri. Lasciando intendere che su questo \\u00E8 pronto a tornare al voto. Ma - se i 5Stelle sul tema hanno aperto - il presidente del Consiglio non sembra disposto a tollerare un flat tax finanziata in deficit. Perch\\u00E9 significherebbe la sfida finale all'Ue.repApprofondimentoFico-Salvini, lite sui rom per accelerare la crisidi CARMELO LOPAPAIl consiglio dei ministriIl premier Conte sar\\u00E0 - mercoled\\u00EC e gioved\\u00EC - in visita in Vietnan. Salvini ha lasciato intendere che vorrebbe un Consiglio dei ministri venerd\\u00EC: \\\"Finalmente sar\\u00E0 approvato il decreto sicurezza bis contro scafisti, camorristi, spacciatori, teppisti da stadio\\\", ha detto. Ma, al di l\\u00E0 del decreto sicurezza bis - di cui tanto si \\u00E8 discusso nelle ultime settimane - la riunione potrebbe essere il momento della resa dei conti su tutti i nodi in sospeso. Tutti intorno a un tavolo, Conte e i due vicepremier. E tra i tanti temi di divisione c'\\u00E8 - e non \\u00E8 secondario - quello delle autonomie.\", \"sottotitolo\":\"Il ministro Centinaio a Circo Massimo: \\\"Faccia un miracolo o si va al voto\\\". Prevista anche una riunione sullo sblocca-cantieri a Palazzo Chigi. Nei prossimi giorni una serie di appuntamenti potrebbero essere l'occasione per uno scontro finale tra Lega e 5Stelle\", \"tags\":[\"\",\"governo conte\",\"lettera Ue\",\"Commissione Ue\",\"lega\",\"Circo Massimo\",\"Giuseppe Conte\",\"Luigi Di Maio\",\"Matteo Salvini\",\"Gian Marco Centinaio\"]}\n",
    "p = {\"titolo_articolo\":\"La bella storia di Vittorio Zucconi\", \"sottotitolo\":\"I ricordi di una vita, i personaggi incrociati: in edicola con \\\"Repubblica\\\" il libro del grande giornalista scomparso: \\\"Il lato fresco del cuscino\\\"\",\"tags\":[\"Libri\",\"Vittorio Zucconi\"],\"testo\":\"Tra gli umani sentimenti ingiustamente additati c'è con ogni evidenza l'invidia. Più che un peccato, rappresenta un bivio. Successivo a una consapevolezza, e cioè che l'altro sia più bravo di te. Puoi dolertene, puoi accettarlo. E vivere abbastanza sereno ugualmente. Con uno sprone in più.Io ero e sono invidioso di Vittorio Zucconi. Della sua qualità di scrittura, della sua leggerezza corposa, del suo approccio laterale al mondo. Uno che stava da Papa a Mosca come a Washington, passando per Milano Marittima, con l'attitudine, col tempo anche fisica, di un Hemingway della tigella al pesto.In questi giorni maldestri, in cui microbi della Storia come il senatore Pillon hanno inteso riversare la propria miseria su chi ne aveva disvelato, via radio, la rotonda inutilità, molti hanno ricordato l'attitudine a romanzare di Vittorio. Qualcuno, specie i senza talento, con una punta di derisione.Ma era gente che al bivio di cui sopra aveva preso la strada che porta alla frustrazione. Quelli che, quando muore uno figo, vorrebbero che quei commenti fossero per loro. Né vale citare l'antico adagio giornalistico, inutilmente cinico, secondo cui una bella storia non dovrebbe mai essere rovinata con la verità.Quella di Zucconi è la verità. La sua. Viva, umanissima. Brillante. Innervata da quella deriva amorosa con la reazione all'imprevisto, lo scatto di reni sul girar di rotative, la notizia da riconoscere al balzo, che solo i giornalisti migliori, cioè gli interpreti più nobili di un mestiere che, nonostante tutto rimane nobile a sua volta, sanno pescare in loro stessi.Un bel libro parte spesso da un bel titolo. Nella parte fresca del cuscino c'è l'immagine di una requie che ognuno di noi ha cercato almeno una volta nella vita. Leggi quella frase e senti la guancia sulla federa. Così come, nell'incedere delle pagine, immagini la grisaglia di Mike Bongiorno nel casermone in cui abitava il papà di Vittorio, Guglielmo. Vedi il flan di piselli che assaggiava. Immagini la Bianchina su cui il giovane Zucconi si ribalta senza conseguenze, come una Comaneci dell'autoscontro. Vedi, fisicamente, l'aeroplanino di latta fatto coi resti delle bibite lasciate dagli americani in Vietnam, o la vecchietta che spaccia orologi sovietici destinati a fermarsi in un lampo di Perestrojika.Sei con lui, sei lui. C'è una finitezza ostentata, quasi autoavverante, lungo i capitoli di quello che non è un libro triste. Ma ha il tono malinconico e allegro del bilancio.C'è una fila di chiuse, come diciamo noi tossici del piombo (da stampa) che valgono il singolo capitolo. Compongono, tutte insieme, quasi una frase di senso compiuto: \\\"Nessuno dovrà mai deporre un santino per un robot\\\". \\\"Se avessi avuto ancora con me il mio vecchio computer, sono sicuro che finalmente avrebbe saputo scrivere un bel racconto\\\". \\\"La rivoluzione non finirà con un'esplosione, ma con un giocattolo\\\". \\\"Era finita la mia giovinezza\\\".Nell'esegesi postuma da cui le persone realmente ironiche andrebbero esentate per decreto, qualcuno ha inteso divaricare lo Zucconi social, quello radiofonico, il cronista, lo scrittore, come se i primi due rivestissero minor dignità. Le crociate contro l'analfabetismo grillino, i duetti di giornalismo carpiato con Edoardo Buffoni, le sue corrispondenze, questo libro, sono invece tutti figli degli stessi lombi. Quelli di un fuoriclasse.Narciso, generoso, coraggioso, creativo, entusiasta. Scegliete l'aggettivo che preferite e applicatelo: avrete il \\\"vostro\\\" Vittorio Zucconi. Come lui aveva sempre la sua storia da raccontare.Qui, ora.Ancora.Il libro di Vittorio Zucconi, \\\"Il lato fresco del cuscino\\\", sarà in vendita da domani con Repubblica al prezzo di 9,90 euro più il costo del giornale \"}\n",
    "x_1 = preproc([p])\n",
    "\n",
    "ldac.predict([' '.join(x_1[0]['testo'] +x_1[0]['titolo_articolo']+x_1[0]['sottotitolo'] + x_1[0]['tags'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrice di confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title(\"Matrice di confusione\")\n",
    "cm = confusion_matrix(test_cats, pred_cats)\n",
    "    \n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.colorbar(fraction=0.04, pad=0.1)#spazi occupati dalla barra a destra\n",
    "\n",
    "#labels \n",
    "tick_marks = range(len(classi))\n",
    "plt.xticks(tick_marks, classi, rotation=90)\n",
    "plt.yticks(tick_marks, classi)\n",
    "    \n",
    "plt.grid(None)\n",
    "plt.ylabel(\"Classe osservata\")\n",
    "plt.xlabel(\"Classe prevista\")\n",
    "\n",
    "thresh = cm.max() / 2\n",
    "#colore dei numeri dentro i quadrati\n",
    "for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuratezza ottenuta e tabella riassuntiva per classe con Classificatore logistico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(pred_cats, test_cats)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_cats, pred_cats, target_names=unique_labels(test_cats, pred_cats)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuratezza ottenuta e tabella riassuntiva per classe con Classificatore Albero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(pred_cats, test_cats)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_cats, pred_cats, target_names=unique_labels(test_cats, pred_cats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-6a56d8e309a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mldax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'online'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mldax_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mldax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_texts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    564\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0midx_slice\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m                         self._em_step(X[idx_slice, :], total_samples=n_samples,\n\u001b[1;32m--> 566\u001b[1;33m                                       batch_update=False, parallel=parallel)\n\u001b[0m\u001b[0;32m    567\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m                     \u001b[1;31m# batch update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py\u001b[0m in \u001b[0;36m_em_step\u001b[1;34m(self, X, total_samples, batch_update, parallel)\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[1;31m# E-step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         _, suff_stats = self._e_step(X, cal_sstats=True, random_init=True,\n\u001b[1;32m--> 453\u001b[1;33m                                      parallel=parallel)\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[1;31m# M-step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py\u001b[0m in \u001b[0;36m_e_step\u001b[1;34m(self, X, cal_sstats, random_init, parallel)\u001b[0m\n\u001b[0;32m    404\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_change_tol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcal_sstats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                                               random_state)\n\u001b[1;32m--> 406\u001b[1;33m             for idx_slice in gen_even_slices(X.shape[0], n_jobs))\n\u001b[0m\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[1;31m# merge result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py\u001b[0m in \u001b[0;36m_update_doc_distribution\u001b[1;34m(X, exp_topic_word_distr, doc_topic_prior, max_iters, mean_change_tol, cal_sstats, random_state)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             doc_topic_d = (exp_doc_topic_d *\n\u001b[1;32m--> 119\u001b[1;33m                            np.dot(cnts / norm_phi, exp_topic_word_d.T))\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[1;31m# Note: adds doc_topic_prior to doc_topic_d, in-place.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             _dirichlet_expectation_1d(doc_topic_d, doc_topic_prior,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import tqdm\n",
    "\n",
    "tf = CountVectorizer(ngram_range=(1,6), min_df=8,max_df=0.9,encoding='utf-8',max_features=1000000, lowercase=True).fit(train_texts)\n",
    "tf_train = tf.transform(train_texts)\n",
    "ldax = LatentDirichletAllocation(n_components=16,max_iter=50, learning_method='online',random_state=0).fit(tf_train.toarray())\n",
    "ldax_train = ldax.transform(tf_train.toarray())\n",
    "tf_test = tf.transform(test_texts)\n",
    "ldax_test = ldax.transform(tf_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Profondità dell'albero allenato senza restrizioni: {}\".format(ldac.named_steps[\"classifier\"].max_depth))\n",
    "print(\"Massimo numero minimo di osservazioni in una foglia: {}\".format(len(train_texts) // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "param_grid = ParameterGrid({\n",
    "    'classifier__max_depth': np.arange(1, 18),\n",
    "    'classifier__min_samples_leaf': 2 ** np.arange(0,10),\n",
    "})\n",
    "print(param_grid.param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "risultati = []\n",
    "\n",
    "for params in tqdm.tqdm(param_grid):\n",
    "    ldac.set_params(**params)\n",
    "    ldac.fit(ldax_train, train_cats)\n",
    "    y_pred = ldac.predict(ldax_test)\n",
    "    params[\"accuracy_score\"] = metrics.accuracy_score(test_cats, y_pred)\n",
    "    risultati.append(params)\n",
    "\n",
    "risultati = pd.DataFrame(risultati).sort_values([\"accuracy_score\", \"classifier__max_depth\"], ascending=[False, True])\n",
    "risultati.reset_index(drop=True, inplace=True)\n",
    "print(\"Primi 5:\")\n",
    "display(risultati.head())\n",
    "\n",
    "print(\"Ultimi 5:\")\n",
    "risultati.tail()\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 4640)\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 2400 samples in 0.003s...\n",
      "[t-SNE] Computed neighbors for 2400 samples in 0.214s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 2400\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 2400\n",
      "[t-SNE] Computed conditional probabilities for sample 2400 / 2400\n",
      "[t-SNE] Mean sigma: 0.005675\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 62.775581\n",
      "[t-SNE] KL divergence after 1000 iterations: -1.118988\n"
     ]
    }
   ],
   "source": [
    "from plotly.plotly import iplot\n",
    "import plotly as pl\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from plotly.graph_objs import Scatter3d, Data, Marker\n",
    "\n",
    "params = {\n",
    "    'count_mx__ngram_range': (1, 8),\n",
    "    'count_mx__min_df': 13,\n",
    "    'count_mx__max_df': 0.9,\n",
    "    'lda__n_components':8,\n",
    "    'lda__learning_decay':0.5,\n",
    "    'classifier__min_samples_leaf': 1,\n",
    "    'classifier__max_depth': 15\n",
    "}\n",
    "\n",
    "#####Costruisci la term document matrix e poi cerca\n",
    "documents = [' '.join([word for word in x['testo']] + x['tags'] + x['sottotitolo'] + x['titolo_articolo']) for x in dati_preprocessati if x['categoria']!= \"Cultura & Spettacoli\"]\n",
    "labels = np.array([x['categoria'] for x in dati_preprocessati])\n",
    "#print documents\n",
    "no_features = 300000\n",
    "tf_vectorizer = CountVectorizer(ngram_range=(1,8), min_df=13, max_df=0.9,encoding='utf-8',max_features=no_features, lowercase=True)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "print(tf.shape)\n",
    "###Creamo i cluster con LDA\n",
    "\n",
    "no_topics = 8\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=no_topics,max_iter=100,learning_decay=0.5, learning_method='online',random_state=0).fit(tf)\n",
    "\n",
    "#'lda__n_components': 6, 'lda__learning_decay': 0.7, 'count_mx__ngram_range': (1, 12), 'count_mx__min_df': 14, 'count_mx__max_df': 70\n",
    "X_topics = lda.fit_transform(tf)\n",
    "\n",
    "# Fit the model using t-SNE randomized algorithm\n",
    "tsne_model = TSNE(n_components=3, verbose=1, random_state=0, init='pca')\n",
    "# N-D -> 2-D\n",
    "tsne_lda = tsne_model.fit_transform(X_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristy\\Anaconda3\\lib\\site-packages\\plotly\\graph_objs\\_deprecations.py:426: DeprecationWarning:\n",
      "\n",
      "plotly.graph_objs.Marker is deprecated.\n",
      "Please replace it with one of the following more specific types\n",
      "  - plotly.graph_objs.scatter.Marker\n",
      "  - plotly.graph_objs.histogram.selected.Marker\n",
      "  - etc.\n",
      "\n",
      "\n",
      "C:\\Users\\Cristy\\Anaconda3\\lib\\site-packages\\plotly\\graph_objs\\_deprecations.py:39: DeprecationWarning:\n",
      "\n",
      "plotly.graph_objs.Data is deprecated.\n",
      "Please replace it with a list or tuple of instances of the following types\n",
      "  - plotly.graph_objs.Scatter\n",
      "  - plotly.graph_objs.Bar\n",
      "  - plotly.graph_objs.Area\n",
      "  - plotly.graph_objs.Histogram\n",
      "  - etc.\n",
      "\n",
      "\n",
      "C:\\Users\\Cristy\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cristi.gutzu/5.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from plotly.plotly import iplot\n",
    "import plotly as pl\n",
    "import numpy as np\n",
    "from plotly.graph_objs import Scatter3d, Data, Marker\n",
    "\n",
    "colormap = np.array([\n",
    "    \"#f7fe72\", \"#731dd8\", \"#ffc857\", \"#40c9a2\",\"#00100b\", \"#757761\",\n",
    "])\n",
    "\n",
    "# First three dimensions from reduced X VS the Y\n",
    "walkers = []\n",
    "\n",
    "trace0 = Scatter3d(\n",
    "    x=tsne_lda[0:399, 0],\n",
    "    y=tsne_lda[0:399, 1],\n",
    "    z=tsne_lda[0:399, 2], \n",
    "    marker=Marker(color=colormap[0], colorscale='Portland'),\n",
    "    mode='markers'\n",
    ")\n",
    "\n",
    "trace1 = Scatter3d(\n",
    "    x=tsne_lda[400:799, 0],\n",
    "    y=tsne_lda[400:799, 1],\n",
    "    z=tsne_lda[400:799, 2], \n",
    "    marker=Marker(color=colormap[1], colorscale='Portland'),\n",
    "    mode='markers'\n",
    ")\n",
    "\n",
    "trace2 = Scatter3d(\n",
    "    x=tsne_lda[800:1199, 0],\n",
    "    y=tsne_lda[800:1199, 1],\n",
    "    z=tsne_lda[800:1199, 2], \n",
    "    marker=Marker(color=colormap[2], colorscale='Portland'),\n",
    "    mode='markers'\n",
    ")\n",
    "\n",
    "trace3 = Scatter3d(\n",
    "    x=tsne_lda[1200:1599, 0],\n",
    "    y=tsne_lda[1200:1599, 1],\n",
    "    z=tsne_lda[1200:1599, 2], \n",
    "    marker=Marker(color=colormap[3], colorscale='Portland'),\n",
    "    mode='markers'\n",
    ")\n",
    "\n",
    "trace4 = Scatter3d(\n",
    "    x=tsne_lda[1600:1999, 0],\n",
    "    y=tsne_lda[1600:1999, 1],\n",
    "    z=tsne_lda[1600:1999, 2], \n",
    "    marker=Marker(color=colormap[4], colorscale='Portland'),\n",
    "    mode='markers'\n",
    ")\n",
    "\n",
    "trace5 = Scatter3d(\n",
    "    x=tsne_lda[2000:2399, 0],\n",
    "    y=tsne_lda[2000:2399, 1],\n",
    "    z=tsne_lda[2000:2399, 2], \n",
    "    marker=Marker(color=colormap[5], colorscale='Portland'),\n",
    "    mode='markers'\n",
    ")\n",
    "\n",
    "walkers.append(trace0)\n",
    "walkers.append(trace1)\n",
    "walkers.append(trace2)\n",
    "walkers.append(trace3)\n",
    "walkers.append(trace4)\n",
    "walkers.append(trace5)\n",
    "\n",
    "data = Data(walkers) \n",
    "pl.tools.set_credentials_file(username='cristi.gutzu', api_key='S4SFAPdXM3dUxDF0wmxT')\n",
    "iplot(data, filename = 'pca-cloud')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
