{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.plotting import save\n",
    "\n",
    "import inspect\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from numpy import linalg\n",
    "from numpy.linalg import norm\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "import nltk\n",
    "from os import listdir\n",
    "import re\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "\n",
    "\n",
    "# Importing sklearn and TSNE.\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import scale\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "# We'll hack a bit with the t-SNE code in sklearn.\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.manifold.t_sne import (_joint_probabilities,\n",
    "                                    _kl_divergence)\n",
    "#from sklearn.utils.extmath import _ravel\n",
    "# Random state we define this random state to use this value in TSNE which is a randmized algo.\n",
    "RS = 25111993\n",
    "\n",
    "# Importing matplotlib for graphics.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import json\n",
    "from string import punctuation\n",
    "\n",
    "import string \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing seaborn to make nice plots.\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1582,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FUNZIONI NECESSARIE PER ESTRAZIONE DATI DAGLI ARTICOLI PER POI CREARE LA TERM DOCUMENT MATRIX\n",
    "\n",
    "def news_analyzer(news, tokenizer, stemmer, stop_words):\n",
    "    # ============== YOUR CODE HERE ==============\n",
    "    campi_interesse = ['testo','titolo_articolo','sottotitolo']\n",
    "    for campo in campi_interesse:\n",
    "        #apostrofi fix\n",
    "        news[campo] = BeautifulSoup(news[campo], \"lxml\").get_text()\n",
    "        news[campo] = news[campo].replace(\"'\",\" \")\n",
    "        news[campo] = re.sub(\"http\\S+\", \" link \", news[campo])\n",
    "        news[campo] = tokenizer.tokenize(news[campo])\n",
    "        news[campo] = [token for token in news[campo] if not token.isdigit() and token not in stop_words]\n",
    "        news[campo] = [stemmer.stem(token) for token in news[campo] if not token.isdigit() and token not in stop_words]\n",
    "    # ============================================\n",
    "\n",
    "    return news\n",
    "\n",
    "def preproc(news_dir):\n",
    "    nltk.download(\"stopwords\")\n",
    "    stop_words = stopwords.words('italian') + list(punctuation)\n",
    "    stemmer = SnowballStemmer(\"italian\")\n",
    "    tokenizer = TweetTokenizer(\n",
    "        preserve_case=False,\n",
    "        strip_handles=True\n",
    "    )\n",
    "    X_train =  []\n",
    "    onlyfiles = [f for f in listdir(news_dir) if isfile(join(news_dir, f))]\n",
    "    for articolo in onlyfiles:\n",
    "        docJson = open(news_dir+articolo,\"r\")\n",
    "        jsonData = json.loads(docJson.read())\n",
    "\n",
    "        X_train.append(jsonData)\n",
    "        docJson.close()\n",
    "\n",
    "    return [news_analyzer(news, tokenizer, stemmer, stop_words) for news in tqdm.tqdm(X_train)]\n",
    "\n",
    "# An user defined function to create scatter plot of vectors\n",
    "def scatter(x, colors):\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette = np.array(sns.color_palette(\"hls\", 8))\n",
    "\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(32, 32))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=120,\n",
    "                    c=palette[colors.astype(np.int)])\n",
    "    #plt.xlim(-25, 25)\n",
    "    #plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each cluster.\n",
    "    txts = []\n",
    "    for i in range(18):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=50)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "\n",
    "    return f, ax, sc, txts\n",
    "def distribuzione_frequenze(tf):\n",
    "    tdf = np.sum(tf.toarray(), axis=0)\n",
    "    df ={}\n",
    "    for i in tdf:\n",
    "        if i in df:\n",
    "            df[i] += 1\n",
    "        else:\n",
    "            df[i] = 1\n",
    "\n",
    "    k = sorted(df.keys())\n",
    "    freq = [k,[]]\n",
    "    for x in freq[0]:\n",
    "        freq[1].append(df[x])\n",
    "    return (freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1578,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Cristy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 200/200 [00:01<00:00, 186.85it/s]\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Cristy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 199/199 [00:01<00:00, 143.68it/s]\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Cristy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 200/200 [00:01<00:00, 159.06it/s]\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Cristy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 200/200 [00:00<00:00, 252.24it/s]\n"
     ]
    }
   ],
   "source": [
    "economia = preproc(\"C:/Users/Cristy/Documents/Universita/big_data/articoli_economia/\")\n",
    "cultura = preproc(\"C:/Users/Cristy/Documents/Universita/big_data/articoli_cultura/\")\n",
    "tech = preproc(\"C:/Users/Cristy/Documents/Universita/big_data/articoli_tech/\")\n",
    "politica = preproc(\"C:/Users/Cristy/Documents/Universita/big_data/articoli_politica/\")\n",
    "for articolo in economia:\n",
    "    articolo['categoria'] = \"Economia\"\n",
    "for articolo in cultura:\n",
    "    articolo['categoria'] = \"Cultura\"\n",
    "for articolo in tech:\n",
    "    articolo['categoria'] = \"Tech\"\n",
    "for articolo in politica:\n",
    "    articolo['categoria'] = \"Politica\"\n",
    "dati_preprocessati =  tech + cultura + politica + economia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 4, 5, 6, 7], [13110, 20233, 621, 123, 215, 42]]\n"
     ]
    }
   ],
   "source": [
    "#####Costruisci la term document matrix e poi cerca\n",
    "documents = [' '.join([word for word in x['testo']] + x['tags'] + x['sottotitolo'] + x['titolo_articolo']) for x in dati_preprocessati if x['categoria']!= \"Cultura & Spettacoli\"]\n",
    "labels = np.array([x['categoria'] for x in dati_preprocessati])\n",
    "#print documents\n",
    "no_features = 300000\n",
    "tf_vectorizer = CountVectorizer(ngram_range=(7,7), encoding='utf-8',max_features=no_features, lowercase=True)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "#create dataFrame\n",
    "df = pd.DataFrame(tf.toarray().transpose(), index = tf_vectorizer.get_feature_names())\n",
    "\n",
    "print(distribuzione_frequenze(tf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1767,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34344, 799)\n",
      "799\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(len(documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1768,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creamo i cluster con LDA\n",
    "\n",
    "no_topics = 4\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=no_topics,max_iter=100, learning_method='online',random_state=0).fit(tf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 4)"
      ]
     },
     "execution_count": 1779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_topics = lda.fit_transform(tf)\n",
    "#Correction\n",
    "threshold = 0.1\n",
    "_idx = np.amax(X_topics, axis=1) > threshold  # idx of doc that above the threshold\n",
    "X_topics = X_topics[_idx]\n",
    "X_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1780,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using t-SNE randomized algorithm\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, init='pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1781,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 799 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 799 samples in 0.017s...\n",
      "[t-SNE] Computed conditional probabilities for sample 799 / 799\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 41.932301\n",
      "[t-SNE] KL divergence after 1000 iterations: -0.610364\n"
     ]
    }
   ],
   "source": [
    "# N-D -> 2-D\n",
    "tsne_lda = tsne_model.fit_transform(X_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799"
      ]
     },
     "execution_count": 1782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_topics = X_topics\n",
    "len(_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1783,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 colors\n",
    "colormap = np.array([\n",
    "    \"#1f77b4\", \"#bbc7e8\", \"#cc7f0e\", \"#ddbb78\", \"#2ca02c\",\n",
    "    \"#98df8a\", \"#d62728\", \"#ff9896\", \"#d68728\", \"#459896\",\n",
    "    \"#7cdf8a\", \"#d7cd28\", \"#cfd876\", \"#d7cd28\", \"#7c989d\",\n",
    "    \"#1e22b4\", \"#b187e8\", \"#cc660e\", \"#ddda78\", \"#2c072c\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799"
      ]
     },
     "execution_count": 1784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then we find the most likely topic for each news:\n",
    "_lda_keys = []\n",
    "for i in range(X_topics.shape[0]):\n",
    "  _lda_keys +=  _topics[i].argmax(),\n",
    "\n",
    "len(_lda_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1785,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and get top words for each topic:\n",
    "n_top_words = 5\n",
    "topic_summaries = []\n",
    "topic_word = lda.components_  # all topic words\n",
    "vocab = tf_vectorizer.get_feature_names()\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "  topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words + 1):-1] # get!\n",
    "  topic_summaries.append(' '.join(topic_words)) # append!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1786,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Politica', 'Tech', 'Cultura', 'Economia']"
      ]
     },
     "execution_count": 1786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## title = '1024 articoli ANSA'\n",
    "from bokeh.plotting import figure \n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "print(len(tsne_lda[:,0]))\n",
    "\n",
    "cats = [x['categoria'] for x in dati_preprocessati]\n",
    "testi = [x['testo'] for x in dati_preprocessati]\n",
    "data = { 'x' : tsne_lda[:,0],\n",
    "         'y' :  tsne_lda[:,1],\n",
    "        'content': cats, \n",
    "        'topic_key': [str(x) for x in cats]}\n",
    " \n",
    "source = bp.ColumnDataSource(data)\n",
    "\n",
    "p = figure(plot_width=1100, plot_height=1100, tooltips=\"content: @content - topic: @topic_key\")\n",
    "index_cmap=factor_cmap('topic_key', palette=colormap, factors=list(set([str(x) for x in cats])) )\n",
    "p.circle('x', 'y', size=10, source=source, fill_color=index_cmap)\n",
    "\n",
    "\n",
    "show(p)\n",
    "list(set([str(x) for x in cats]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1778,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1778-debd3a6bd9c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdati_preprocessati\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtopic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_lda_keys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mdistr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'categoria'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Vogliamo un metodo per ottimizare il parametro del countVectorizer.\n",
    "#che e' ngarm range, questo parametro vive in N.\n",
    "\n",
    "from collections import Counter\n",
    "distr = {\"Tech\":[], \"Politica\":[], \"Economia\":[], \"Cultura\":[]}\n",
    "i=0\n",
    "for idex, doc in enumerate(dati_preprocessati):\n",
    "    topic = (_lda_keys[i])\n",
    "    distr[doc['categoria']].append(topic)\n",
    "    i=i+1\n",
    "def CountFrequency(my_list): \n",
    "  \n",
    "    # Creating an empty dictionary  \n",
    "    freq = {} \n",
    "    for item in my_list: \n",
    "        if (item in freq): \n",
    "            freq[item] += 1\n",
    "        else: \n",
    "            freq[item] = 1\n",
    "    lista = [item[1] for item in freq.items()]\n",
    "    for key, value in freq.items(): \n",
    "        print (\"% d : % d\"%(key, value)) \n",
    "        \n",
    "    return (max(lista)/sum(lista))\n",
    "    \n",
    "c1=CountFrequency(distr[\"Tech\"])\n",
    "print(\"#######\")\n",
    "c2=CountFrequency(distr[\"Economia\"])\n",
    "print(\"#######\")\n",
    "\n",
    "c3=CountFrequency(distr[\"Politica\"])\n",
    "print(\"#######\")\n",
    "\n",
    "c4=CountFrequency(distr[\"Cultura\"])\n",
    "\n",
    "indice = (c1+c2+c3+c4)/4\n",
    "print(indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1519,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristy\\Anaconda3\\lib\\site-packages\\bokeh\\io\\saving.py:126: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
      "  warn(\"save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\")\n",
      "C:\\Users\\Cristy\\Anaconda3\\lib\\site-packages\\bokeh\\io\\saving.py:139: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
      "  warn(\"save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Cristy\\\\Documents\\\\Universita\\\\big_data\\\\1024 articoli ANSA.html'"
      ]
     },
     "execution_count": 1519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# randomly choose a news (within a topic) coordinate as the crucial words coordinate\n",
    "topic_coord = np.empty((X_topics.shape[1], 2)) * np.nan\n",
    "for topic_num in _lda_keys:\n",
    "  if not np.isnan(topic_coord).any():\n",
    "    break\n",
    "  topic_coord[topic_num] = tsne_lda[_lda_keys.index(topic_num)]\n",
    "\n",
    "# plot crucial words\n",
    "for i in range(X_topics.shape[1]):\n",
    "  plot_lda.text(topic_coord[i, 0], topic_coord[i, 1], [topic_summaries[i]])\n",
    "\n",
    "# hover tools\n",
    "hover = plot_lda.select(dict(type=HoverTool))\n",
    "hover.tooltips = {\"content\": \"@content - topic: @topic_key\"}\n",
    "\n",
    "# save the plot\n",
    "save(plot_lda, '{}.html'.format(title))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ColumnDataSource in module bokeh.models.sources:\n",
      "\n",
      "class ColumnDataSource(ColumnarDataSource)\n",
      " |  ColumnDataSource(*args, **kw)\n",
      " |  \n",
      " |  Maps names of columns to sequences or arrays.\n",
      " |  \n",
      " |  The ``ColumnDataSource`` is a fundamental data structure of Bokeh. Most\n",
      " |  plots, data tables, etc. will be driven by a ``ColumnDataSource``.\n",
      " |  \n",
      " |  If the ``ColumnDataSource`` initializer is called with a single argument that\n",
      " |  can be any of the following:\n",
      " |  \n",
      " |  * A Python ``dict`` that maps string names to sequences of values, e.g.\n",
      " |    lists, arrays, etc.\n",
      " |  \n",
      " |    .. code-block:: python\n",
      " |  \n",
      " |        data = {'x': [1,2,3,4], 'y': np.ndarray([10.0, 20.0, 30.0, 40.0])}\n",
      " |  \n",
      " |        source = ColumnDataSource(data)\n",
      " |  \n",
      " |  .. note::\n",
      " |      ``ColumnDataSource`` only creates a shallow copy of ``data``. Use e.g.\n",
      " |      ``ColumnDataSource(copy.deepcopy(data))`` if initializing from another\n",
      " |      ``ColumnDataSource.data`` object that you want to keep independent.\n",
      " |  \n",
      " |  * A Pandas ``DataFrame`` object\n",
      " |  \n",
      " |    .. code-block:: python\n",
      " |  \n",
      " |        source = ColumnDataSource(df)\n",
      " |  \n",
      " |    In this case the CDS will have columns corresponding to the columns of\n",
      " |    the ``DataFrame``. If the ``DataFrame`` columns have multiple levels,\n",
      " |    they will be flattened using an underscore (e.g. level_0_col_level_1_col).\n",
      " |    The index of the ``DataFrame`` will be flattened to an ``Index`` of tuples\n",
      " |    if it's a ``MultiIndex``, and then reset using ``reset_index``. The result\n",
      " |    will be a column with the same name if the index was named, or\n",
      " |    level_0_name_level_1_name if it was a named ``MultiIndex``. If the\n",
      " |    ``Index`` did not have a name or the ``MultiIndex`` name could not be\n",
      " |    flattened/determined, the ``reset_index`` function will name the index column\n",
      " |    ``index``, or ``level_0`` if the name ``index`` is not available.\n",
      " |  \n",
      " |  * A Pandas ``GroupBy`` object\n",
      " |  \n",
      " |    .. code-block:: python\n",
      " |  \n",
      " |        group = df.groupby(('colA', 'ColB'))\n",
      " |  \n",
      " |    In this case the CDS will have columns corresponding to the result of\n",
      " |    calling ``group.describe()``. The ``describe`` method generates columns\n",
      " |    for statistical measures such as ``mean`` and ``count`` for all the\n",
      " |    non-grouped original columns. The CDS columns are formed by joining\n",
      " |    original column names with the computed measure. For example, if a\n",
      " |    ``DataFrame`` has columns ``'year'`` and ``'mpg'``. Then passing\n",
      " |    ``df.groupby('year')`` to a CDS will result in columns such as\n",
      " |    ``'mpg_mean'``\n",
      " |  \n",
      " |    If the ``GroupBy.describe`` result has a named index column, then\n",
      " |    CDS will also have a column with this name. However, if the index name\n",
      " |    (or any subname of a ``MultiIndex``) is ``None``, then the CDS will have\n",
      " |    a column generically named ``index`` for the index.\n",
      " |  \n",
      " |    Note this capability to adapt ``GroupBy`` objects may only work with\n",
      " |    Pandas ``>=0.20.0``.\n",
      " |  \n",
      " |  .. note::\n",
      " |      There is an implicit assumption that all the columns in a given\n",
      " |      ``ColumnDataSource`` all have the same length at all times. For this\n",
      " |      reason, it is usually preferable to update the ``.data`` property\n",
      " |      of a data source \"all at once\".\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ColumnDataSource\n",
      " |      ColumnarDataSource\n",
      " |      DataSource\n",
      " |      bokeh.model.Model\n",
      " |      bokeh.core.has_props.HasProps\n",
      " |      bokeh.util.callback_manager.PropertyCallbackManager\n",
      " |      bokeh.util.callback_manager.EventCallbackManager\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *args, **kw)\n",
      " |      If called with a single argument that is a dict or\n",
      " |      ``pandas.DataFrame``, treat that implicitly as the \"data\" attribute.\n",
      " |  \n",
      " |  add(self, data, name=None)\n",
      " |      Appends a new column of data to the data source.\n",
      " |      \n",
      " |      Args:\n",
      " |          data (seq) : new data to add\n",
      " |          name (str, optional) : column name to use.\n",
      " |              If not supplied, generate a name of the form \"Series ####\"\n",
      " |      \n",
      " |      Returns:\n",
      " |          str:  the column name used\n",
      " |  \n",
      " |  patch(self, patches, setter=None)\n",
      " |      Efficiently update data source columns at specific locations\n",
      " |      \n",
      " |      If it is only necessary to update a small subset of data in a\n",
      " |      ``ColumnDataSource``, this method can be used to efficiently update only\n",
      " |      the subset, instead of requiring the entire data set to be sent.\n",
      " |      \n",
      " |      This method should be passed a dictionary that maps column names to\n",
      " |      lists of tuples that describe a patch change to apply. To replace\n",
      " |      individual items in columns entirely, the tuples should be of the\n",
      " |      form:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          (index, new_value)  # replace a single column value\n",
      " |      \n",
      " |          # or\n",
      " |      \n",
      " |          (slice, new_values) # replace several column values\n",
      " |      \n",
      " |      Values at an index or slice will be replaced with the corresponding\n",
      " |      new values.\n",
      " |      \n",
      " |      In the case of columns whose values are other arrays or lists, (e.g.\n",
      " |      image or patches glyphs), it is also possible to patch \"subregions\".\n",
      " |      In this case the first item of the tuple should be a whose first\n",
      " |      element is the index of the array item in the CDS patch, and whose\n",
      " |      subsequent elements are integer indices or slices into the array item:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          # replace the entire 10th column of the 2nd array:\n",
      " |      \n",
      " |            +----------------- index of item in column data source\n",
      " |            |\n",
      " |            |       +--------- row subindex into array item\n",
      " |            |       |\n",
      " |            |       |       +- column subindex into array item\n",
      " |            V       V       V\n",
      " |          ([2, slice(None), 10], new_values)\n",
      " |      \n",
      " |      Imagining a list of 2d NumPy arrays, the patch above is roughly\n",
      " |      equivalent to:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          data = [arr1, arr2, ...]  # list of 2d arrays\n",
      " |      \n",
      " |          data[2][:, 10] = new_data\n",
      " |      \n",
      " |      There are some limitations to the kinds of slices and data that can\n",
      " |      be accepted.\n",
      " |      \n",
      " |      * Negative ``start``, ``stop``, or ``step`` values for slices will\n",
      " |        result in a ``ValueError``.\n",
      " |      \n",
      " |      * In a slice, ``start > stop`` will result in a ``ValueError``\n",
      " |      \n",
      " |      * When patching 1d or 2d subitems, the subitems must be NumPy arrays.\n",
      " |      \n",
      " |      * New values must be supplied as a **flattened one-dimensional array**\n",
      " |        of the appropriate size.\n",
      " |      \n",
      " |      Args:\n",
      " |          patches (dict[str, list[tuple]]) : lists of patches for each column\n",
      " |      \n",
      " |      Returns:\n",
      " |          None\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      The following example shows how to patch entire column elements. In this case,\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          source = ColumnDataSource(data=dict(foo=[10, 20, 30], bar=[100, 200, 300]))\n",
      " |      \n",
      " |          patches = {\n",
      " |              'foo' : [ (slice(2), [11, 12]) ],\n",
      " |              'bar' : [ (0, 101), (2, 301) ],\n",
      " |          }\n",
      " |      \n",
      " |          source.patch(patches)\n",
      " |      \n",
      " |      After this operation, the value of the ``source.data`` will be:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          dict(foo=[11, 22, 30], bar=[101, 200, 301])\n",
      " |      \n",
      " |      For a more comprehensive complete example, see :bokeh-tree:`examples/howto/patch_app.py`.\n",
      " |  \n",
      " |  remove(self, name)\n",
      " |      Remove a column of data.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str) : name of the column to remove\n",
      " |      \n",
      " |      Returns:\n",
      " |          None\n",
      " |      \n",
      " |      .. note::\n",
      " |          If the column name does not exist, a warning is issued.\n",
      " |  \n",
      " |  stream(self, new_data, rollover=None)\n",
      " |      Efficiently update data source columns with new append-only data.\n",
      " |      \n",
      " |      In cases where it is necessary to update data columns in, this method\n",
      " |      can efficiently send only the new data, instead of requiring the\n",
      " |      entire data set to be re-sent.\n",
      " |      \n",
      " |      Args:\n",
      " |          new_data (dict[str, seq]) : a mapping of column names to sequences of\n",
      " |              new data to append to each column.\n",
      " |      \n",
      " |              All columns of the data source must be present in ``new_data``,\n",
      " |              with identical-length append data.\n",
      " |      \n",
      " |          rollover (int, optional) : A maximum column size, above which data\n",
      " |              from the start of the column begins to be discarded. If None,\n",
      " |              then columns will continue to grow unbounded (default: None)\n",
      " |      \n",
      " |      Returns:\n",
      " |          None\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          source = ColumnDataSource(data=dict(foo=[], bar=[]))\n",
      " |      \n",
      " |          # has new, identical-length updates for all columns in source\n",
      " |          new_data = {\n",
      " |              'foo' : [10, 20],\n",
      " |              'bar' : [100, 200],\n",
      " |          }\n",
      " |      \n",
      " |          source.stream(new_data)\n",
      " |  \n",
      " |  to_df(self)\n",
      " |      Convert this data source to pandas ``DataFrame``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          DataFrame\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_df(data) from bokeh.model.MetaModel\n",
      " |      Create a ``dict`` of columns from a Pandas ``DataFrame``,\n",
      " |      suitable for creating a ``ColumnDataSource``.\n",
      " |      \n",
      " |      Args:\n",
      " |          data (DataFrame) : data to convert\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict[str, np.array]\n",
      " |  \n",
      " |  from_groupby(data) from bokeh.model.MetaModel\n",
      " |      Create a ``dict`` of columns from a Pandas ``GroupBy``,\n",
      " |      suitable for creating a ``ColumnDataSource``.\n",
      " |      \n",
      " |      The data generated is the result of running ``describe``\n",
      " |      on the group.\n",
      " |      \n",
      " |      Args:\n",
      " |          data (Groupby) : data to convert\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict[str, np.array]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  column_names\n",
      " |      A list of the column names in this data source.\n",
      " |  \n",
      " |  data\n",
      " |      Mapping of column names to sequences of data. The data can be, e.g,\n",
      " |      Python lists or tuples, NumPy arrays, etc.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __cached_all__overridden_defaults__ = {}\n",
      " |  \n",
      " |  __cached_all__properties__ = {'callback', 'data', 'js_event_callbacks'...\n",
      " |  \n",
      " |  __cached_all__properties_with_refs__ = {'callback', 'js_event_callback...\n",
      " |  \n",
      " |  __container_props__ = {'data'}\n",
      " |  \n",
      " |  __properties__ = {'data'}\n",
      " |  \n",
      " |  __properties_with_refs__ = set()\n",
      " |  \n",
      " |  __view_model__ = 'ColumnDataSource'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from ColumnarDataSource:\n",
      " |  \n",
      " |  selection_policy\n",
      " |      An instance of a ``SelectionPolicy`` that determines how selections are set.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from DataSource:\n",
      " |  \n",
      " |  callback\n",
      " |      A callback to run in the browser whenever the selection is changed.\n",
      " |      \n",
      " |      .. note:\n",
      " |          This property is left for backwards compatibility, but may be deprecated\n",
      " |          in the future. Prefer ``source.selected.js_on_change(...)`` for new code.\n",
      " |  \n",
      " |  selected\n",
      " |      A Selection that indicates selected indices on this ``DataSource``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from bokeh.model.Model:\n",
      " |  \n",
      " |  __repr__ = __str__(self)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  js_on_change(self, event, *callbacks)\n",
      " |      Attach a ``CustomJS`` callback to an arbitrary BokehJS model event.\n",
      " |      \n",
      " |      On the BokehJS side, change events for model properties have the\n",
      " |      form ``\"change:property_name\"``. As a convenience, if the event name\n",
      " |      passed to this method is also the name of a property on the model,\n",
      " |      then it will be prefixed with ``\"change:\"`` automatically:\n",
      " |      \n",
      " |      .. code:: python\n",
      " |      \n",
      " |          # these two are equivalent\n",
      " |          source.js_on_change('data', callback)\n",
      " |          source.js_on_change('change:data', callback)\n",
      " |      \n",
      " |      However, there are other kinds of events that can be useful to respond\n",
      " |      to, in addition to property change events. For example to run a\n",
      " |      callback whenever data is streamed to a ``ColumnDataSource``, use the\n",
      " |      ``\"stream\"`` event on the source:\n",
      " |      \n",
      " |      .. code:: python\n",
      " |      \n",
      " |          source.js_on_change('streaming', callback)\n",
      " |  \n",
      " |  js_on_event(self, event, *callbacks)\n",
      " |  \n",
      " |  layout(self, side, plot)\n",
      " |  \n",
      " |  on_change(self, attr, *callbacks)\n",
      " |      Add a callback on this object to trigger when ``attr`` changes.\n",
      " |      \n",
      " |      Args:\n",
      " |          attr (str) : an attribute name on this object\n",
      " |          *callbacks (callable) : callback functions to register\n",
      " |      \n",
      " |      Returns:\n",
      " |          None\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          widget.on_change('value', callback1, callback2, ..., callback_n)\n",
      " |  \n",
      " |  references(self)\n",
      " |      Returns all ``Models`` that this object has references to.\n",
      " |  \n",
      " |  select(self, selector)\n",
      " |      Query this object and all of its references for objects that\n",
      " |      match the given selector.\n",
      " |      \n",
      " |      Args:\n",
      " |          selector (JSON-like) :\n",
      " |      \n",
      " |      Returns:\n",
      " |          seq[Model]\n",
      " |  \n",
      " |  select_one(self, selector)\n",
      " |      Query this object and all of its references for objects that\n",
      " |      match the given selector.  Raises an error if more than one object\n",
      " |      is found.  Returns single matching object, or None if nothing is found\n",
      " |      Args:\n",
      " |          selector (JSON-like) :\n",
      " |      \n",
      " |      Returns:\n",
      " |          Model\n",
      " |  \n",
      " |  set_select(self, selector, updates)\n",
      " |      Update objects that match a given selector with the specified\n",
      " |      attribute/value updates.\n",
      " |      \n",
      " |      Args:\n",
      " |          selector (JSON-like) :\n",
      " |          updates (dict) :\n",
      " |      \n",
      " |      Returns:\n",
      " |          None\n",
      " |  \n",
      " |  to_json(self, include_defaults)\n",
      " |      Returns a dictionary of the attributes of this object,\n",
      " |      containing only \"JSON types\" (string, number, boolean,\n",
      " |      none, dict, list).\n",
      " |      \n",
      " |      References to other objects are serialized as \"refs\" (just\n",
      " |      the object ID and type info), so the deserializer will\n",
      " |      need to separately have the full attributes of those\n",
      " |      other objects.\n",
      " |      \n",
      " |      There's no corresponding ``from_json()`` because to\n",
      " |      deserialize an object is normally done in the context of a\n",
      " |      Document (since the Document can resolve references).\n",
      " |      \n",
      " |      For most purposes it's best to serialize and deserialize\n",
      " |      entire documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          include_defaults (bool) : whether to include attributes\n",
      " |              that haven't been changed from the default\n",
      " |  \n",
      " |  to_json_string(self, include_defaults)\n",
      " |      Returns a JSON string encoding the attributes of this object.\n",
      " |      \n",
      " |      References to other objects are serialized as references\n",
      " |      (just the object ID and type info), so the deserializer\n",
      " |      will need to separately have the full attributes of those\n",
      " |      other objects.\n",
      " |      \n",
      " |      There's no corresponding ``from_json_string()`` because to\n",
      " |      deserialize an object is normally done in the context of a\n",
      " |      Document (since the Document can resolve references).\n",
      " |      \n",
      " |      For most purposes it's best to serialize and deserialize\n",
      " |      entire documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          include_defaults (bool) : whether to include attributes\n",
      " |              that haven't been changed from the default\n",
      " |  \n",
      " |  trigger(self, attr, old, new, hint=None, setter=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from bokeh.model.Model:\n",
      " |  \n",
      " |  document\n",
      " |      The |Document| this model is attached to (can be ``None``)\n",
      " |  \n",
      " |  id\n",
      " |  \n",
      " |  js_event_callbacks\n",
      " |      A mapping of event names to lists of ``CustomJS`` callbacks.\n",
      " |      \n",
      " |      Typically, rather then modifying this property directly, callbacks should be\n",
      " |      added using the ``Model.js_on_event`` method:\n",
      " |      \n",
      " |      .. code:: python\n",
      " |      \n",
      " |          callback = CustomJS(code=\"console.log('tap event occurred')\")\n",
      " |          plot.js_on_event('tap', callback)\n",
      " |  \n",
      " |  js_property_callbacks\n",
      " |      A mapping of attribute names to lists of ``CustomJS`` callbacks, to be set up on\n",
      " |      BokehJS side when the document is created.\n",
      " |      \n",
      " |      Typically, rather then modifying this property directly, callbacks should be\n",
      " |      added using the ``Model.js_on_change`` method:\n",
      " |      \n",
      " |      .. code:: python\n",
      " |      \n",
      " |          callback = CustomJS(code=\"console.log('stuff')\")\n",
      " |          plot.x_range.js_on_change('start', callback)\n",
      " |  \n",
      " |  name\n",
      " |      An arbitrary, user-supplied name for this model.\n",
      " |      \n",
      " |      This name can be useful when querying the document to retrieve specific\n",
      " |      Bokeh models.\n",
      " |      \n",
      " |      .. code:: python\n",
      " |      \n",
      " |          >>> plot.circle([1,2,3], [4,5,6], name=\"temp\")\n",
      " |          >>> plot.select(name=\"temp\")\n",
      " |          [GlyphRenderer(id='399d53f5-73e9-44d9-9527-544b761c7705', ...)]\n",
      " |      \n",
      " |      .. note::\n",
      " |          No uniqueness guarantees or other conditions are enforced on any names\n",
      " |          that are provided, nor is the name used directly by Bokeh for any\n",
      " |          reason.\n",
      " |  \n",
      " |  ref\n",
      " |      A Bokeh protocol \"reference\" to this model, i.e. a dict of the\n",
      " |      form:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          {\n",
      " |              'type' : << view model name >>\n",
      " |              'id'   : << unique model id >>\n",
      " |          }\n",
      " |      \n",
      " |      Additionally there may be a `subtype` field if this model is a subtype.\n",
      " |  \n",
      " |  subscribed_events\n",
      " |      List of events that are subscribed to by Python callbacks. This is\n",
      " |      the set of events that will be communicated from BokehJS back to\n",
      " |      Python for this model.\n",
      " |  \n",
      " |  tags\n",
      " |      An optional list of arbitrary, user-supplied values to attach to this\n",
      " |      model.\n",
      " |      \n",
      " |      This data can be useful when querying the document to retrieve specific\n",
      " |      Bokeh models:\n",
      " |      \n",
      " |      .. code:: python\n",
      " |      \n",
      " |          >>> r = plot.circle([1,2,3], [4,5,6])\n",
      " |          >>> r.tags = [\"foo\", 10]\n",
      " |          >>> plot.select(tags=['foo', 10])\n",
      " |          [GlyphRenderer(id='1de4c3df-a83d-480a-899b-fb263d3d5dd9', ...)]\n",
      " |      \n",
      " |      Or simply a convenient way to attach any necessary metadata to a model\n",
      " |      that can be accessed by ``CustomJS`` callbacks, etc.\n",
      " |      \n",
      " |      .. note::\n",
      " |          No uniqueness guarantees or other conditions are enforced on any tags\n",
      " |          that are provided, nor are the tags used directly by Bokeh for any\n",
      " |          reason.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from bokeh.core.has_props.HasProps:\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Intercept attribute setting on HasProps in order to special case\n",
      " |      a few situations:\n",
      " |      \n",
      " |      * short circuit all property machinery for ``_private`` attributes\n",
      " |      * suggest similar attribute names on attribute errors\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str) : the name of the attribute to set on this object\n",
      " |          value (obj) : the value to set\n",
      " |      \n",
      " |      Returns:\n",
      " |          None\n",
      " |  \n",
      " |  apply_theme(self, property_values)\n",
      " |      Apply a set of theme values which will be used rather than\n",
      " |      defaults, but will not override application-set values.\n",
      " |      \n",
      " |      The passed-in dictionary may be kept around as-is and shared with\n",
      " |      other instances to save memory (so neither the caller nor the\n",
      " |      |HasProps| instance should modify it).\n",
      " |      \n",
      " |      Args:\n",
      " |          property_values (dict) : theme values to use in place of defaults\n",
      " |      \n",
      " |      Returns:\n",
      " |          None\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Structural equality of models.\n",
      " |      \n",
      " |      Args:\n",
      " |          other (HasProps) : the other instance to compare to\n",
      " |      \n",
      " |      Returns:\n",
      " |          True, if properties are structurally equal, otherwise False\n",
      " |  \n",
      " |  properties_with_values(self, include_defaults=True)\n",
      " |      Collect a dict mapping property names to their values.\n",
      " |      \n",
      " |      This method *always* traverses the class hierarchy and includes\n",
      " |      properties defined on any parent classes.\n",
      " |      \n",
      " |      Non-serializable properties are skipped and property values are in\n",
      " |      \"serialized\" format which may be slightly different from the values\n",
      " |      you would normally read from the properties; the intent of this method\n",
      " |      is to return the information needed to losslessly reconstitute the\n",
      " |      object instance.\n",
      " |      \n",
      " |      Args:\n",
      " |          include_defaults (bool, optional) :\n",
      " |              Whether to include properties that haven't been explicitly set\n",
      " |              since the object was created. (default: True)\n",
      " |      \n",
      " |      Returns:\n",
      " |         dict : mapping from property names to their values\n",
      " |  \n",
      " |  query_properties_with_values(self, query, include_defaults=True)\n",
      " |      Query the properties values of |HasProps| instances with a\n",
      " |      predicate.\n",
      " |      \n",
      " |      Args:\n",
      " |          query (callable) :\n",
      " |              A callable that accepts property descriptors and returns True\n",
      " |              or False\n",
      " |      \n",
      " |          include_defaults (bool, optional) :\n",
      " |              Whether to include properties that have not been explicitly\n",
      " |              set by a user (default: True)\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict : mapping of property names and values for matching properties\n",
      " |  \n",
      " |  set_from_json(self, name, json, models=None, setter=None)\n",
      " |      Set a property value on this object from JSON.\n",
      " |      \n",
      " |      Args:\n",
      " |          name: (str) : name of the attribute to set\n",
      " |      \n",
      " |          json: (JSON-value) : value to set to the attribute to\n",
      " |      \n",
      " |          models (dict or None, optional) :\n",
      " |              Mapping of model ids to models (default: None)\n",
      " |      \n",
      " |              This is needed in cases where the attributes to update also\n",
      " |              have values that have references.\n",
      " |      \n",
      " |          setter(ClientSession or ServerSession or None, optional) :\n",
      " |              This is used to prevent \"boomerang\" updates to Bokeh apps.\n",
      " |      \n",
      " |              In the context of a Bokeh server application, incoming updates\n",
      " |              to properties will be annotated with the session that is\n",
      " |              doing the updating. This value is propagated through any\n",
      " |              subsequent change notifications that the update triggers.\n",
      " |              The session can compare the event setter to itself, and\n",
      " |              suppress any updates that originate from itself.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None\n",
      " |  \n",
      " |  themed_values(self)\n",
      " |      Get any theme-provided overrides.\n",
      " |      \n",
      " |      Results are returned as a dict from property name to value, or\n",
      " |      ``None`` if no theme overrides any values for this instance.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict or None\n",
      " |  \n",
      " |  unapply_theme(self)\n",
      " |      Remove any themed values and restore defaults.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None\n",
      " |  \n",
      " |  update(self, **kwargs)\n",
      " |      Updates the object's properties from the given keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |          The following are equivalent:\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              from bokeh.models import Range1d\n",
      " |      \n",
      " |              r = Range1d\n",
      " |      \n",
      " |              # set properties individually:\n",
      " |              r.start = 10\n",
      " |              r.end = 20\n",
      " |      \n",
      " |              # update properties together:\n",
      " |              r.update(start=10, end=20)\n",
      " |  \n",
      " |  update_from_json(self, json_attributes, models=None, setter=None)\n",
      " |      Updates the object's properties from a JSON attributes dictionary.\n",
      " |      \n",
      " |      Args:\n",
      " |          json_attributes: (JSON-dict) : attributes and values to update\n",
      " |      \n",
      " |          models (dict or None, optional) :\n",
      " |              Mapping of model ids to models (default: None)\n",
      " |      \n",
      " |              This is needed in cases where the attributes to update also\n",
      " |              have values that have references.\n",
      " |      \n",
      " |          setter(ClientSession or ServerSession or None, optional) :\n",
      " |              This is used to prevent \"boomerang\" updates to Bokeh apps.\n",
      " |      \n",
      " |              In the context of a Bokeh server application, incoming updates\n",
      " |              to properties will be annotated with the session that is\n",
      " |              doing the updating. This value is propagated through any\n",
      " |              subsequent change notifications that the update triggers.\n",
      " |              The session can compare the event setter to itself, and\n",
      " |              suppress any updates that originate from itself.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from bokeh.core.has_props.HasProps:\n",
      " |  \n",
      " |  dataspecs() from bokeh.model.MetaModel\n",
      " |      Collect the names of all ``DataSpec`` properties on this class.\n",
      " |      \n",
      " |      This method *always* traverses the class hierarchy and includes\n",
      " |      properties defined on any parent classes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          set[str] : names of ``DataSpec`` properties\n",
      " |  \n",
      " |  dataspecs_with_props() from bokeh.model.MetaModel\n",
      " |      Collect a dict mapping the names of all ``DataSpec`` properties\n",
      " |      on this class to the associated properties.\n",
      " |      \n",
      " |      This method *always* traverses the class hierarchy and includes\n",
      " |      properties defined on any parent classes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict[str, DataSpec] : mapping of names and ``DataSpec`` properties\n",
      " |  \n",
      " |  lookup(name) from bokeh.model.MetaModel\n",
      " |      Find the ``PropertyDescriptor`` for a Bokeh property on a class,\n",
      " |      given the property name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str) : name of the property to search for\n",
      " |      \n",
      " |      Returns:\n",
      " |          PropertyDescriptor : descriptor for property named ``name``\n",
      " |  \n",
      " |  properties(with_bases=True) from bokeh.model.MetaModel\n",
      " |      Collect the names of properties on this class.\n",
      " |      \n",
      " |      This method *optionally* traverses the class hierarchy and includes\n",
      " |      properties defined on any parent classes.\n",
      " |      \n",
      " |      Args:\n",
      " |          with_bases (bool, optional) :\n",
      " |              Whether to include properties defined on parent classes in\n",
      " |              the results. (default: True)\n",
      " |      \n",
      " |      Returns:\n",
      " |         set[str] : property names\n",
      " |  \n",
      " |  properties_containers() from bokeh.model.MetaModel\n",
      " |      Collect the names of all container properties on this class.\n",
      " |      \n",
      " |      This method *always* traverses the class hierarchy and includes\n",
      " |      properties defined on any parent classes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          set[str] : names of container properties\n",
      " |  \n",
      " |  properties_with_refs() from bokeh.model.MetaModel\n",
      " |      Collect the names of all properties on this class that also have\n",
      " |      references.\n",
      " |      \n",
      " |      This method *always* traverses the class hierarchy and includes\n",
      " |      properties defined on any parent classes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          set[str] : names of properties that have references\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from bokeh.core.has_props.HasProps:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from bokeh.util.callback_manager.PropertyCallbackManager:\n",
      " |  \n",
      " |  remove_on_change(self, attr, *callbacks)\n",
      " |      Remove a callback from this object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from bokeh.util.callback_manager.EventCallbackManager:\n",
      " |  \n",
      " |  on_event(self, event, *callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(bp.ColumnDataSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
